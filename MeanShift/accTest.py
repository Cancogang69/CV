import numpy as np
import cv2
import os
from matplotlib import pyplot as plt

def read_data(path, dir_name):
  frame_file = open(os.path.join(path, dir_name + "_frames.txt"))
  start_frame, end_frame = [int(float(x)) for x in frame_file.read().split(",")]
  groundtruth_file = os.path.join(path, dir_name + "_gt.txt")
  gt = []
  with open(groundtruth_file) as file:
    for line in file:
      gt.append([int(float(x)) for x in line.strip().split(",")])
  frame_path = os.path.join(path, "img")
  frames = []
  for filename in os.listdir(frame_path):
    if(filename.endswith(".jpg") == False):
      continue
    img = cv2.imread(os.path.join(frame_path, filename))
    if img is not None:
        frames.append(img)
  if(len(frames)<end_frame):
    back = end_frame - len(frames)
    start_frame -= back
    end_frame -= back
  return start_frame, end_frame, gt, frames

def IoU(ground_truth, pred):
  # coordinates of the area of intersection.
  ix1 = np.maximum(ground_truth[0], pred[0])
  iy1 = np.maximum(ground_truth[1], pred[1])
  ix2 = np.minimum(ground_truth[0] + ground_truth[2], pred[0] + pred[2])
  iy2 = np.minimum(ground_truth[1] + ground_truth[3], pred[1] + pred[3])
    
  # Intersection height and width.
  i_height = np.maximum(iy2 - iy1 + 1, np.array(0.))
  i_width = np.maximum(ix2 - ix1 + 1, np.array(0.))
    
  area_of_intersection = i_height * i_width
    
  # Ground Truth dimensions.
  gt_height = ground_truth[3] + 1
  gt_width = ground_truth[2] + 1
    
  # Prediction dimensions.
  pd_height = pred[3] + 1
  pd_width = pred[2] + 1
    
  area_of_union = gt_height * gt_width + pd_height * pd_width - area_of_intersection
    
  iou = area_of_intersection / area_of_union
    
  return iou

def remove_background(img):
  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  # onvert image to black and white
  _, image_edges = cv2.threshold(gray_img, 100, 255, cv2.THRESH_BINARY)

  # create background mask
  mask = np.zeros(img.shape, np.uint8)
  mask.fill(255)

  # get most significant contours
  contours_mask, _ = cv2.findContours(image_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

  # most significant contours traversal
  for contour in range(len(contours_mask)):
    # create mask
    if contour != 1:
      cv2.fillConvexPoly(mask, contours_mask[contour], (0, 0, 0))

  img = cv2.bitwise_and(img, mask)
  return img

def remove_background2(img, bbox):
  mask = np.zeros(img.shape[:2], dtype="uint8")
  fgModel = np.zeros((1, 65), dtype="float")
  bgModel = np.zeros((1, 65), dtype="float")
  (mask, bgModel, fgModel) = cv2.grabCut(img, mask, bbox, bgModel,
                                         fgModel, mode=cv2.GC_INIT_WITH_RECT)
  values = (
	("Definite Background", cv2.GC_BGD),
	("Probable Background", cv2.GC_PR_BGD),
	("Definite Foreground", cv2.GC_FGD),
	("Probable Foreground", cv2.GC_PR_FGD),
  )

  for (name, value) in values:
    # construct a mask that for the current value
    print("[INFO] showing mask for '{}'".format(name))
    valueMask = (mask == value).astype("uint8") * 255
	# display the mask so we can visualize it
    cv2.imshow(name, valueMask)
    cv2.waitKey(0)
  # we'll set all definite background and probable background pixels
  # to 0 while definite foreground and probable foreground pixels are
  # set to 1
  outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),
    0, 1)
  # scale the mask from the range [0, 1] to [0, 255]
  outputMask = (outputMask * 255).astype("uint8")
  # apply a bitwise AND to the image using our mask generated by
  # GrabCut to generate our final output image
  output = cv2.bitwise_and(img, img, mask=outputMask)
  return output
  

def mean_shift(start_frame, end_frame, gt, frames, debug=False):
  # take first frame of the video
  first_frame = frames[start_frame]

  # setup initial location of window
  # track_window = [topLeftX, topLeftY, width, height]
  track_window = gt[0]
  # set up the ROI for tracking
  x, y, w, h = track_window
  roi = first_frame[int(y):int(y+h), int(x):int(x+w)]

  ff_rmbg = remove_background2(first_frame, track_window)
  #roi = remove_background(roi)

  #channel 0 is hue and 1 is value
  #h_bins, v_bins = hue and value levels
  h_bins = 30
  v_bins = 32
  histSize = [h_bins, v_bins]
  h_range = [0, 180]
  v_range = [0, 256]
  ranges = h_range + v_range # Concat list
  channels = [0, 2]
  #convert roi to hsv color space
  hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
  #calculate and normalize histogram of roi
  hist_roi = cv2.calcHist([hsv_roi], channels, None, histSize, ranges, accumulate=False)
  cv2.normalize(hist_roi, hist_roi, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
  
  TP = 0
  FP = 0
  
  # Setup the termination criteria, either 10 iteration or move by at least 1 pt
  term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

  for i in range(start_frame+1, end_frame):
    frame = frames[i]
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    dst = cv2.calcBackProject([hsv], channels, hist_roi, ranges, 1)
    
    # apply meanshift to get the new location
    ret, track_window = cv2.meanShift(dst, track_window, term_crit)

    gt_index = i - start_frame
    
    if(IoU(gt[gt_index], track_window) >= 0.5):
      TP+=1
    else:
      FP+=1
  return TP, FP

path = [".\\Airport_ce\\Airport_ce", ".\\Basketball\\Basketball", ".\\Busstation_ce1\\Busstation_ce1"]
dir_name = ["Airport_ce", "Basketball", "Busstation_ce1"]
item = 2
start_frame, end_frame, gt, frames = read_data(path[item], dir_name[item])
TP, FP = mean_shift(start_frame, end_frame, gt, frames, True)
print(TP/(TP+FP))